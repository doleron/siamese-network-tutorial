{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is: 3.11.2 (main, Mar 27 2023, 23:42:44) [GCC 11.2.0]\n",
      "Tensorflow version is: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disabling verbose tf logging\n",
    "\n",
    "# uncomment the following line if you want to force CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Python version is: \" + sys.version)\n",
    "print(\"Tensorflow version is: \" + tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 360 images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dataset_path = \"custom_face_database\"\n",
    "\n",
    "files = [os.path.join(r,file) for r,d,f in os.walk(dataset_path) for file in f]\n",
    "\n",
    "file_size = len(files)\n",
    "\n",
    "print(\"We have \" + str(file_size) + \" images.\")\n",
    "\n",
    "random.shuffle(files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating classes and labels\n",
    "\n",
    "Let's define the label for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 classes:  ['megan_rapinoe' 'obama' 'priyanka_chopra' 'mbappe' 'chris_emsworth'\n",
      " 'meryl_streep' 'bia_miranda' 'idris_elba' 'katty_perry' 'lula'\n",
      " 'nicolas_cage' 'brad_pitt' 'elon_musk' 'angelababy' 'messi']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_instances(files, classes = []):\n",
    "    labels = []\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "        clazz = file.split(\"/\")[-2]\n",
    "        \n",
    "        if classes.count(clazz):\n",
    "            label = classes.index(clazz)\n",
    "        else:\n",
    "            label = len(classes)\n",
    "            classes.append(clazz)\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(labels), np.array(classes)\n",
    "\n",
    "labels, classes = make_instances(files)\n",
    "CLASSES_SIZE = len(classes)\n",
    "\n",
    "print(str(CLASSES_SIZE) + \" classes: \", classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating class-balanced training and validation sets\n",
    "\n",
    "Here the idea is generating the training and validation set in such way 80% of files of each class are within the training data and the remaining 20% are in the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = []\n",
    "training_labels = []\n",
    "validation_files = []\n",
    "validation_labels = []\n",
    "\n",
    "for label in range(CLASSES_SIZE):\n",
    "    indexes = np.where(labels == label)[0]\n",
    "\n",
    "    threshold = len(indexes) * 80 // 100\n",
    "\n",
    "    training_indexes = indexes[0:threshold]\n",
    "    training_files_for_class = [files[i] for i in training_indexes]\n",
    "\n",
    "    training_files.extend(training_files_for_class)\n",
    "    training_labels.extend([label] * len(training_files_for_class))\n",
    "\n",
    "    validation_indexes = indexes[threshold:]\n",
    "    validation_files_for_class = [files[i] for i in validation_indexes]\n",
    "\n",
    "    validation_files.extend(validation_files_for_class)\n",
    "    validation_labels.extend([label] * len(validation_files_for_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['megan_rapinoe' 'obama' 'priyanka_chopra' 'mbappe' 'chris_emsworth'\n",
      " 'meryl_streep' 'bia_miranda' 'idris_elba' 'katty_perry' 'lula'\n",
      " 'nicolas_cage' 'brad_pitt' 'elon_musk' 'angelababy' 'messi']\n",
      "285\n",
      "285\n",
      "75\n",
      "75\n",
      "['custom_face_database/megan_rapinoe/Selection_019 (1).png', 'custom_face_database/megan_rapinoe/Selection_015.png', 'custom_face_database/megan_rapinoe/Selection_023.png', 'custom_face_database/megan_rapinoe/Selection_022.png']\n",
      "[0, 0, 0, 0]\n",
      "['custom_face_database/megan_rapinoe/Selection_017.png', 'custom_face_database/megan_rapinoe/Selection_014.png', 'custom_face_database/megan_rapinoe/Selection_017 (1).png', 'custom_face_database/megan_rapinoe/Selection_022 (1).png']\n",
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(classes)\n",
    "\n",
    "print(len(training_files))\n",
    "print(len(training_labels))\n",
    "print(len(validation_files))\n",
    "print(len(validation_labels))\n",
    "\n",
    "print(training_files[0:4])\n",
    "print(training_labels[0:4])\n",
    "\n",
    "print(validation_files[0:4])\n",
    "print(validation_labels[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    n = min([len(digit_indices[d]) for d in range(CLASSES_SIZE)]) - 1\n",
    "    \n",
    "    for d in range(CLASSES_SIZE):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, CLASSES_SIZE)\n",
    "            dn = (d + inc) % CLASSES_SIZE\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "            \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_pairs_on_set(images, labels):\n",
    "    \n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(CLASSES_SIZE)]\n",
    "    pairs, y = create_pairs(images, digit_indices)\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    return pairs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files = np.array(training_files)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "validation_files = np.array(validation_files)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_pairs, training_pairs_labels = create_pairs_on_set(training_files, training_labels)\n",
    "validation_pairs, validation_pairs_labels = create_pairs_on_set(validation_files, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n",
      "75\n",
      "540\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(training_files))\n",
    "print(len(validation_files))\n",
    "print(len(training_pairs))\n",
    "print(len(validation_pairs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training & validation datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "As any machine learning model, Siamese Networks are also prone to overfitting or underfitting. In order to avoid overfitting almost as possible, we will introduce augmented data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.01),\n",
    "    tf.keras.layers.RandomBrightness(factor=0.2, value_range=(0., 1.)),\n",
    "    tf.keras.layers.GaussianNoise(0.002)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 244\n",
    "TRAINING_BATCH_SIZE = 8\n",
    "\n",
    "def load_image(file_name):\n",
    "    raw = tf.io.read_file(file_name)\n",
    "    image = tf.io.decode_image(raw, expand_animations = False, channels=3)\n",
    "    image = tf.image.resize(image, size=(INPUT_SIZE, INPUT_SIZE), preserve_aspect_ratio=True)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, INPUT_SIZE, INPUT_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def load_images(pair):\n",
    "    img_A = load_image(pair[0])\n",
    "    img_B = load_image(pair[1])\n",
    "    return (img_A, img_B)\n",
    "\n",
    "def build_training_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(training_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(training_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (load_images(pair), label))\n",
    "    result = result.shuffle(100, reshuffle_each_iteration=True)\n",
    "    result = result.repeat()\n",
    "    result = result.batch(TRAINING_BATCH_SIZE)\n",
    "    result = result.map(lambda pair, y: ((data_augmentation(pair[0], training=True),data_augmentation(pair[1], training=True)), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "train_ds = build_training_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_dataset(dataset, instances, batch_size, rows_per_image):\n",
    "\n",
    "    img_size = 1\n",
    "\n",
    "    fig = plt.figure(layout='constrained', figsize=(img_size*2, img_size*rows_per_image))\n",
    "    subfigs = fig.subfigures(rows_per_image, img_size, wspace=0.07)\n",
    "    subfigs = subfigs.flatten()\n",
    "    row = 0\n",
    "    for images, labels in dataset.take(instances):\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            img_A = (images[0][i].numpy()*255).astype(\"uint8\")\n",
    "            img_B = (images[1][i].numpy()*255).astype(\"uint8\")\n",
    "            label = labels[i].numpy()\n",
    "\n",
    "            axs = subfigs[row % rows_per_image].subplots(1, 2, sharey=True)\n",
    "\n",
    "            axs[0].imshow(img_A)\n",
    "            axs[0].axis(\"off\")\n",
    "            axs[1].imshow(img_B)\n",
    "            axs[1].axis(\"off\")\n",
    "\n",
    "            subfigs[row % rows_per_image].suptitle(str(label), fontsize=8)\n",
    "            row += 1\n",
    "            if row % rows_per_image == 0:\n",
    "                fig\n",
    "                fig = plt.figure(layout='constrained', figsize=(img_size*2, img_size*rows_per_image))\n",
    "                subfigs = fig.subfigures(rows_per_image, img_size, wspace=0.07)\n",
    "                subfigs = subfigs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(train_ds, 4, TRAINING_BATCH_SIZE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_BATCH_SIZE = 2\n",
    "\n",
    "def build_validation_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(validation_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(validation_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (load_images(pair), label))\n",
    "    result = result.batch(VALIDATION_BATCH_SIZE)\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "validation_ds = build_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(validation_ds, 4, VALIDATION_BATCH_SIZE, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (INPUT_SIZE, INPUT_SIZE, 3)\n",
    "\n",
    "def initialize_base_network():\n",
    "\n",
    "    inputs = tf.keras.layers.Input(INPUT_SHAPE)\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=INPUT_SHAPE, include_top=False, weights='imagenet')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "          \n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(64)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buid_model():\n",
    "    \n",
    "    base_network = initialize_base_network()\n",
    "\n",
    "    input_a = Input(shape=INPUT_SHAPE, name=\"left_input\")\n",
    "    vect_output_a = base_network(input_a)\n",
    "\n",
    "    input_b = Input(shape=INPUT_SHAPE, name=\"right_input\")\n",
    "    vect_output_b = base_network(input_b)\n",
    "\n",
    "    output = Lambda(euclidean_distance, name=\"output_layer\", output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "\n",
    "    return Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buid_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Precision(tf.keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, name='precision', **kwargs):\n",
    "    super(Precision, self).__init__(name=name, **kwargs)\n",
    "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "    self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.math.less(y_pred, 0.5) \n",
    "\n",
    "    true_positives_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "    true_positives_values = tf.cast(true_positives_values, self.dtype)\n",
    "\n",
    "    false_positives_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "    false_positives_values = tf.cast(false_positives_values, self.dtype)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "      true_positives_sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "      true_positives_sample_weight = tf.broadcast_to(true_positives_sample_weight, true_positives_values.shape)\n",
    "      true_positives_values = tf.multiply(true_positives_values, true_positives_sample_weight)\n",
    "\n",
    "      false_positives_sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "      false_positives_sample_weight = tf.broadcast_to(false_positives_sample_weight, false_positives_values.shape)\n",
    "      false_positives_values = tf.multiply(false_positives_values, false_positives_sample_weight)\n",
    "\n",
    "    self.true_positives.assign_add(tf.reduce_sum(true_positives_values))\n",
    "    self.false_positives.assign_add(tf.reduce_sum(false_positives_values))\n",
    "\n",
    "  def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "\n",
    "  def result(self):\n",
    "    result = self.true_positives / (self.true_positives + self.false_positives)\n",
    "    return result\n",
    "\n",
    "class Recall(tf.keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, name='recall', **kwargs):\n",
    "    super(Recall, self).__init__(name=name, **kwargs)\n",
    "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "    self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.math.less(y_pred, 0.5) \n",
    "\n",
    "    true_positives_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "    true_positives_values = tf.cast(true_positives_values, self.dtype)\n",
    "\n",
    "    false_negatives_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "    false_negatives_values = tf.cast(false_negatives_values, self.dtype)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "      true_positives_sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "      true_positives_sample_weight = tf.broadcast_to(true_positives_sample_weight, true_positives_values.shape)\n",
    "      true_positives_values = tf.multiply(true_positives_values, true_positives_sample_weight)\n",
    "\n",
    "      false_negatives_sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "      false_negatives_sample_weight = tf.broadcast_to(false_negatives_sample_weight, false_negatives_values.shape)\n",
    "      false_negatives_values = tf.multiply(false_negatives_values, false_negatives_sample_weight)\n",
    "\n",
    "    self.true_positives.assign_add(tf.reduce_sum(true_positives_values))\n",
    "    self.false_negatives.assign_add(tf.reduce_sum(false_negatives_values))\n",
    "\n",
    "  def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n",
    "\n",
    "  def result(self):\n",
    "    result = self.true_positives / (self.true_positives + self.false_negatives)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              metrics=[Precision(), Recall()])\n",
    "\n",
    "history = model.fit(train_ds, steps_per_epoch=(len(training_pairs) // TRAINING_BATCH_SIZE),\n",
    "                    validation_data=validation_ds,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.ylim(0, 2.)\n",
    "plt.plot(history.history['loss'], color='blue', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='green', label='val_loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(y_true, y_pred):\n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    for actual, distance in zip(y_true, y_pred):\n",
    "        if actual > 0 and distance < .5:\n",
    "            TP += 1\n",
    "        elif actual > 0 and distance >= .5:\n",
    "            FN += 1\n",
    "        elif actual < 1 and distance < .5:\n",
    "            FP += 1\n",
    "        elif actual < 1 and distance >= .5:\n",
    "            TN += 1\n",
    "\n",
    "    precision = float('nan')\n",
    "    recall = float('nan')\n",
    "    if (TP + FP) > 0 :\n",
    "        precision = TP / (TP + FP)\n",
    "    if (TP + FN) > 0 :\n",
    "        recall = TP / (TP + FN)\n",
    "\n",
    "    return precision, recall, TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "loss = model.evaluate(validation_ds)\n",
    "\n",
    "y_pred_test = model.predict(validation_ds)\n",
    "\n",
    "test_y = np.concatenate([y for x, y in validation_ds], axis=0)\n",
    "test_precision, test_recall, TP, TN, FP, FN = compute_performance(test_y, y_pred_test)\n",
    "\n",
    "print(\"Test Loss = {}, Test Precision = {}, Test Recall = {}\".format(loss, test_precision, test_recall))\n",
    "print(\"TP = {}, TN = {}, FP = {}, FN = {}\".format(TP, TN, FP, FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_pairs(rows_per_image = 10, test_instances = 10):\n",
    "\n",
    "    fig = plt.figure(layout='constrained', figsize=(2*2, 2*rows_per_image))\n",
    "    subfigs = fig.subfigures(rows_per_image, 1, wspace=0.07)\n",
    "    subfigs = subfigs.flatten()\n",
    "    row = 0\n",
    "    for images, labels in validation_ds.take(test_instances):\n",
    "\n",
    "        predictions = model.predict(images)\n",
    "        for i in range(VALIDATION_BATCH_SIZE):\n",
    "\n",
    "            axs = subfigs[row % rows_per_image].subplots(1, 2, sharey=True)\n",
    "\n",
    "            img_A = (images[0][i].numpy()*255).astype(\"uint8\")\n",
    "            img_B = (images[1][i].numpy()*255).astype(\"uint8\")\n",
    "            label = labels[i].numpy()\n",
    "\n",
    "            prediction = predictions[i][0]\n",
    "        \n",
    "            bgcolor = (1, 1, 1)\n",
    "            if (label > 0 and prediction >= 0.5) or (label < 1 and prediction < 0.5):\n",
    "                bgcolor = (1, 0, 0)\n",
    "\n",
    "            axs[0].imshow(img_A)\n",
    "            axs[0].axis(\"off\")\n",
    "            axs[1].imshow(img_B)\n",
    "            axs[1].axis(\"off\")\n",
    "            title_fmt = \"Distance is {distance:.4f} for {similarity} images\"\n",
    "            if label > 0:\n",
    "                title = title_fmt.format(distance = prediction, similarity = \"SIMILAR\")\n",
    "            else:\n",
    "                title = title_fmt.format(distance = prediction, similarity = \"different\")\n",
    "\n",
    "            subfigs[row % rows_per_image].suptitle(title, fontsize=8)\n",
    "            row += 1\n",
    "            if row % rows_per_image == 0:\n",
    "                fig\n",
    "                fig = plt.figure(layout='constrained', figsize=(2*2, 2*rows_per_image))\n",
    "                subfigs = fig.subfigures(rows_per_image, 1, wspace=0.07)\n",
    "                subfigs = subfigs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_test_pairs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
